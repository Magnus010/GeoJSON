{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.geos import TopologicalError\n",
    "\n",
    "from multiprocessing import Pool\n",
    "pool = Pool() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_zip3_polygons(jsonfile):\n",
    "    # load GeoJSON file containing sectors\n",
    "    with open(jsonfile, 'r') as zip3f:\n",
    "        zip3js = json.load(zip3f)\n",
    "\n",
    "    # Builds list of zip3 polygons. Corrects invalid shape geometry.\n",
    "    zip3_polygon_list = []\n",
    "    for zip3_feature in zip3js['features']:\n",
    "        zip3_polygon = shape(zip3_feature['geometry'])\n",
    "        if zip3_polygon.is_valid:\n",
    "            zip3_polygon_list.append( (zip3_polygon, zip3_feature[\"properties\"]['ZIP']) ) \n",
    "        else:\n",
    "            zip3_polygon_list.append( (zip3_polygon.buffer(0), zip3_feature[\"properties\"]['ZIP']) )\n",
    "\n",
    "    return zip3_polygon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloads csv files, places in csv folder\n",
    "def grab_files(dl):\n",
    "    file_list = []\n",
    "    file_url = 'http://aqsdr1.epa.gov/aqsweb/aqstmp/airdata/'\n",
    "    if not os.path.isdir('csv'):\n",
    "        os.system('mkdir csv')\n",
    "    for i in xrange(6):\n",
    "        file_list.append(dl + str(i) + '.csv')\n",
    "    for fl in file_list:\n",
    "        if not os.path.isfile(os.path.join('csv',fl)):\n",
    "            zipfile = fl[:-4] + '.zip'\n",
    "            os.system('wget ' + file_url + zipfile)\n",
    "            os.system('unzip ' + zipfile + ' -d csv')\n",
    "            os.system('rm -rf ' + zipfile)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loads data into dictionary of coordinates\n",
    "# Output: { ( lon, lat ) : { date : value } }\n",
    "def load_data_file(filename):\n",
    "    coord_dict = {}\n",
    "    for file in filename:\n",
    "        csv_file = csv.DictReader(open(os.path.join('csv',file)))\n",
    "        for idx, row in enumerate(csv_file):\n",
    "            #sys.stdout.write('\\r')\n",
    "            #sys.stdout.write(\"%d\" % (idx))\n",
    "            #sys.stdout.flush()\n",
    "            lon = float(row[\"Longitude\"])\n",
    "            lat = float(row[\"Latitude\"])\n",
    "            coord = (lon,lat)\n",
    "            date = datetime.datetime.strptime(row['Date Local'], '%Y-%m-%d').date()\n",
    "            value = float(row['1st Max Value'])\n",
    "            try:\n",
    "                coord_dict[coord][date] = value\n",
    "            except KeyError:\n",
    "                coord_dict[coord] = {date:value}\n",
    "            \n",
    "    return coord_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def state_for_zip(zip3):\n",
    "    state_hash = {\n",
    "        'Mississippi': ['386-397'],\n",
    "        'Oklahoma': ['730-731', '734-741', '743-749'],\n",
    "        'Delaware': ['197-199'],\n",
    "        'Minnesota': ['550-551', '553-566'],\n",
    "        'Alaska': ['995-999'],\n",
    "        'Illinois': ['600-620', '622-629'],\n",
    "        'Arkansas': ['716-729'],\n",
    "        'New Mexico': ['870-875', '877-884'],\n",
    "        'Indiana': ['460-470', '472-479'],\n",
    "        'Maryland': ['206-212', '214-219'],\n",
    "        'Louisiana': ['700-701', '703-708', '710-714'],\n",
    "        'Texas': ['733-733', '750-799', '885-885'],\n",
    "        'Wyoming': ['820-831'],\n",
    "        'Tennessee': ['370-385'],\n",
    "        'Armed Forces Americas': ['340-340'],\n",
    "        'Iowa': ['500-528'],\n",
    "        'Arizona': ['850-850', '852-853', '855-857', '859-860', '863-865'],\n",
    "        'Guam': ['969-969'],\n",
    "        'Michigan': ['480-499'],\n",
    "        'Kansas': ['660-662', '664-679'],\n",
    "        'Utah': ['840-847'],\n",
    "        'Virginia': ['201-201', '220-246'],\n",
    "        'Oregon': ['970-979'],\n",
    "        'Puerto Rico': ['006-007', '009-009'],\n",
    "        'Connecticut': ['060-069'],\n",
    "        'Virgin Islands': ['008-008'],\n",
    "        'New Hampshire': ['030-038'],\n",
    "        'Massachusetts': ['010-027', '055-055'],\n",
    "        'West Virginia': ['247-268'],\n",
    "        'South Carolina': ['290-299'],\n",
    "        'California': ['900-908', '910-928', '930-961'],\n",
    "        'Wisconsin': ['530-532', '534-535', '537-549'],\n",
    "        'Vermont': ['050-054', '056-059'],\n",
    "        'Georgia': ['300-319', '398-399'],\n",
    "        'North Dakota': ['567-567', '580-588'],\n",
    "        'Pennsylvania': ['150-196'],\n",
    "        'Armed Forces Europe*': ['090-099'],\n",
    "        'Florida': ['320-339', '341-342', '344-344', '346-347', '349-349'],\n",
    "        'Hawaii': ['967-968'],\n",
    "        'Kentucky': ['400-427', '471-471'],\n",
    "        'Rhode Island': ['028-029'],\n",
    "        'Nebraska': ['680-681', '683-693'],\n",
    "        'Armed Forces Pacific': ['962-966'],\n",
    "        'District of Columbia': ['200-200', '202-205'],\n",
    "        'Ohio': ['430-459'],\n",
    "        'Alabama': ['350-352', '354-369'],\n",
    "        'South Dakota': ['570-577'],\n",
    "        'Colorado': ['800-816'],\n",
    "        'Idaho': ['832-838'],\n",
    "        'New Jersey': ['070-089'],\n",
    "        'Missouri': ['630-631', '633-641', '644-658'],\n",
    "        'Washington': ['980-986', '988-994'],\n",
    "        'North Carolina': ['270-289'],\n",
    "        'New York': ['005-005', '100-149'],\n",
    "        'Montana': ['590-599'],\n",
    "        'Nevada': ['889-891', '893-895', '897-898'],\n",
    "        'Maine': ['039-049']}\n",
    "    \n",
    "    for state in state_hash:\n",
    "        for interval in state_hash[state]:\n",
    "            lower = interval.split(\"-\")[0]\n",
    "            upper = interval.split(\"-\")[1]\n",
    "            if lower==upper and lower==zip3:\n",
    "                return state\n",
    "            \n",
    "            if int(lower) <= int(zip3) and int(zip3) < int(upper):\n",
    "                return state\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes input as longitude first, then latitude\n",
    "# West is negative\n",
    "# Returns zip3\n",
    "def point_check(lon,lat, zip3_polygon_list):\n",
    "    point = Point(lon, lat)\n",
    "    # check each zip 3 polygon to see if it contains the point\n",
    "    for poly in zip3_polygon_list:\n",
    "        if poly[0].contains(point):\n",
    "            #print 'Found in zip3:', zip3_feature['properties']['ZIP']\n",
    "            #print\n",
    "            return str(poly[1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populates zip3 and state dict for value lookups\n",
    "# zip3_dict  := { 'zip3'  : { ( lon, lat ) : { date : value } } }\n",
    "# state_dict := { 'State' : { ( lon, lat ) : { date : value } } }\n",
    "def populate_dicts(coord_dict,zip3_polygon_list):\n",
    "    zip3_dict = {}\n",
    "    state_dict = {}\n",
    "    for coord in coord_dict.keys():\n",
    "        try:\n",
    "            zip3 = point_check(coord[0],coord[1],zip3_polygon_list)\n",
    "        except TopologicalError:\n",
    "            zip3 = None\n",
    "\n",
    "        try:\n",
    "            zip3_dict[str(zip3)][coord] = coord_dict[coord]\n",
    "        except KeyError:\n",
    "            zip3_dict[str(zip3)] = {coord:coord_dict[coord]}\n",
    "\n",
    "        try:\n",
    "            state = state_for_zip(zip3)\n",
    "        except TypeError:\n",
    "            state = 'None'\n",
    "\n",
    "        try:\n",
    "            state_dict[state][coord] = coord_dict[coord]\n",
    "        except KeyError:\n",
    "            state_dict[state] = {coord:coord_dict[coord]}\n",
    "\n",
    "    return zip3_dict, state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prints zip3 graph\n",
    "def zip3_graph(zip3,begin,end,zip3_dict):\n",
    "    timeline_dict = {}\n",
    "    graph_x_list = []\n",
    "    graph_y_list = []\n",
    "    begin_date = datetime.datetime.strptime(begin,'%m-%d-%Y').date()\n",
    "    end_date = datetime.datetime.strptime(end,'%m-%d-%Y').date()\n",
    "    try:\n",
    "        for coord in zip3_dict[zip3].keys():\n",
    "            for date in zip3_dict[zip3][coord]:\n",
    "                if date >= begin_date and date <= end_date:\n",
    "                    value = zip3_dict[zip3][coord][date]\n",
    "                    lon = coord[0] \n",
    "                    lat = coord[1]\n",
    "\n",
    "                    try:\n",
    "                        sub_total = timeline_dict[date][0]*timeline_dict[date][1]\n",
    "                        num_pts = timeline_dict[date][1]+1\n",
    "                        timeline_dict[date][0] = (sub_total + value)/num_pts\n",
    "                        timeline_dict[date][1] = num_pts\n",
    "                        timeline_dict[date][2].append( { ( lon, lat ) : value } )\n",
    "                    except KeyError:\n",
    "                        timeline_dict[date] = [ value, 1, [ { ( lon, lat ) : value } ] ]\n",
    "\n",
    "        for date in sorted(timeline_dict.keys()):\n",
    "            graph_x_list.append(date)\n",
    "            graph_y_list.append(timeline_dict[date][0])\n",
    "\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "        plt.plot(graph_x_list,graph_y_list,marker='o')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Values in zip3 '+str(zip3)+' per Date')\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.show()\n",
    "        \n",
    "    except KeyError:\n",
    "        print \"No data for zip3 \" + str(zip3)\n",
    "\n",
    "    # { Date : [Average, num pts, [{(lat,long):value}...]] }\n",
    "    #return timeline_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prints state graph\n",
    "def state_graph(state,begin,end,state_dict):\n",
    "    timeline_dict = {}\n",
    "    graph_x_list = []\n",
    "    graph_y_list = []\n",
    "    begin_date = datetime.datetime.strptime(begin,'%m-%d-%Y').date()\n",
    "    end_date = datetime.datetime.strptime(end,'%m-%d-%Y').date()\n",
    "    try:\n",
    "        for coord in state_dict[state].keys():\n",
    "            for date in state_dict[state][coord]:\n",
    "                if date >= begin_date and date <= end_date:\n",
    "                    value = state_dict[state][coord][date]\n",
    "                    lon = coord[0] \n",
    "                    lat = coord[1]\n",
    "\n",
    "                    try:\n",
    "                        sub_total = timeline_dict[date][0]*timeline_dict[date][1]\n",
    "                        num_pts = timeline_dict[date][1]+1\n",
    "                        timeline_dict[date][0] = (sub_total + value)/num_pts\n",
    "                        timeline_dict[date][1] = num_pts\n",
    "                        timeline_dict[date][2].append( { ( lon, lat ) : value } )\n",
    "                    except KeyError:\n",
    "                        timeline_dict[date] = [ value, 1, [ { ( lon, lat ) : value } ] ]\n",
    "\n",
    "        for date in sorted(timeline_dict.keys()):\n",
    "            graph_x_list.append(date)\n",
    "            graph_y_list.append(timeline_dict[date][0])\n",
    "\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "        plt.plot(graph_x_list,graph_y_list,marker='o')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Values in '+str(state)+' per Date')\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.show()\n",
    "    \n",
    "    except KeyError:\n",
    "        print \"No data for state \" + str(state)\n",
    "\n",
    "    # { Date : [Average, num pts, [{(lat,long):value}...]] }\n",
    "    #return timeline_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates average value of points in specific radius\n",
    "# [ Average, num pts,  { nearest k ( lon, lat ) : min_dist_km } , distance [km], [{(lat,long):value}...]]\n",
    "# Example:\n",
    "\n",
    "#print range_check(-105.002332,39.746389,20,'01-01-2010','12-31-2015',ozone_state_dict)\n",
    "\n",
    "#Output:\n",
    "#[0.046, 10, {(-104.987625, 39.751184): 1.3496702992280396}, 0.015468932542359015, \n",
    "#[{(-105.13948, 39.638781): 0.058}, {(-105.099973, 39.800333): 0.031}, {(-104.94984, 39.838119): 0.06},\n",
    "#{(-104.987625, 39.751184): 0.053}, {(-105.070358, 39.534488): 0.061}, {(-104.998113, 39.704005): 0.011},\n",
    "#{(-105.177989, 39.743724): 0.061}, {(-104.957193, 39.567887): 0.025}, {(-105.00518, 39.77949): 0.049},\n",
    "#{(-105.030681, 39.751761): 0.051}]]\n",
    "\n",
    "# 0.046 is the average of all points\n",
    "# 10 is the number of points\n",
    "# {(-104.987625, 39.751184): 1.3496702992280396} is the nearest point to the provided lon, lat\n",
    "# (-104.987625, 39.751184) is the coordinates of the nearest point\n",
    "# 1.3496702992280396 is the value of the nearest point\n",
    "# 0.015468932542359015 is the distance of the nearest point to the provided lon, lat\n",
    "# [{(-105.13948, 39.638781): 0.058}, {(-105.099973, 39.800333): 0.031}, {(-104.94984, 39.838119): 0.06},\n",
    "# {(-104.987625, 39.751184): 0.053}, {(-105.070358, 39.534488): 0.061}, {(-104.998113, 39.704005): 0.011},\n",
    "# {(-105.177989, 39.743724): 0.061}, {(-104.957193, 39.567887): 0.025}, {(-105.00518, 39.77949): 0.049},\n",
    "# {(-105.030681, 39.751761): 0.051}]] is the list of points used in calculations\n",
    "# (-105.13948, 39.638781) is the coordinates of the point\n",
    "# 0.058 is the value of the point\n",
    "def range_check(lon,lat,radius,begin,end,state_dict):\n",
    "    input_point = Point(lon,lat)\n",
    "    \n",
    "    # Convert radius (in km) to relative lon/lat coordinate distance\n",
    "    # Technically, it doesn't calculate out this neatly due to the curvature of the earth\n",
    "    # But, for small radius calculations, it should be okay\n",
    "    ##Distance calculation: about 5 km (used site http://www.movable-type.co.uk/scripts/latlong.html)\n",
    "    #x1 = 5\n",
    "    #y1 = Point(-104.94402,39.743).distance(Point(-105.002332,39.746389))\n",
    "    ##Distance calculation: about 1 km\n",
    "    #x2 = 1\n",
    "    #y2 = Point(-105.01317,39.743).distance(Point(-105.002332,39.746389))\n",
    "    #m = (y2-y1)/(x2-x1)\n",
    "    ## y = mx+b\n",
    "    #b = y2-m*x2\n",
    "    #print \"y = \" + str(m) + \"x + \" + str(b)\n",
    "    #y = 0.0117637226171x + -0.000408214482298\n",
    "    \n",
    "    coordinate_distance = 0.0117637226171*radius + -0.000408214482298\n",
    "\n",
    "    local_list = []\n",
    "    point_list = []\n",
    "    min_distance = np.inf\n",
    "    begin_date = datetime.datetime.strptime(begin,'%m-%d-%Y').date()\n",
    "    end_date = datetime.datetime.strptime(end,'%m-%d-%Y').date()\n",
    "    for state in state_dict.keys():\n",
    "        try:\n",
    "            for coord in state_dict[state]:\n",
    "                for date in state_dict[state][coord]:\n",
    "                    if date >= begin_date and date <= end_date:\n",
    "                        lon = coord[0]\n",
    "                        lat = coord[1]\n",
    "                        value = state_dict[state][coord][date]\n",
    "                        entry_point = Point(lon,lat)\n",
    "                        if input_point.distance(entry_point) <= coordinate_distance:\n",
    "                            local_list.append(value)\n",
    "                            point_list.append( { ( lon, lat ) : value } )\n",
    "                            if input_point.distance(entry_point) < min_distance:\n",
    "                                min_distance = input_point.distance(entry_point)\n",
    "                                min_dist_km = (min_distance + 0.000408214482298)/0.0117637226171\n",
    "                                min_point = { ( lon, lat ) : min_dist_km }\n",
    "        except KeyError:\n",
    "            print \"No data for state \" + str(state)\n",
    "            return None\n",
    "    try:\n",
    "        average = sum(local_list)/len(local_list)\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "    \n",
    "    num_pts = len(local_list)\n",
    "    \n",
    "    return [ average, num_pts, min_point, min_distance, point_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self-intersection at or near point -78.778527906282719 43.017714979730926\n",
      "Self-intersection at or near point -81.12325396391924 37.681599524236759\n",
      "Self-intersection at or near point -117.80283229921857 33.706457898118025\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    jsonfile = 'zip3.json'\n",
    "    zip3_database = build_zip3_polygons(jsonfile)\n",
    "    \n",
    "    # file name prefixes to be downloaded from http://aqsdr1.epa.gov/aqsweb/aqstmp/airdata/download_files.html\n",
    "    ozone = 'daily_44201_201'\n",
    "    so2   = 'daily_42401_201'\n",
    "    co    = 'daily_42101_201'\n",
    "    no2   = 'daily_42602_201'\n",
    "    \n",
    "    ozone_file_list = grab_files(ozone)\n",
    "    so2_file_list = grab_files(so2)\n",
    "    co_file_list = grab_files(co)\n",
    "    no2_file_list = grab_files(no2)\n",
    "    \n",
    "    # This part takes time to execute\n",
    "    # I think I parallelized this section....\n",
    "    # Original code execution:\n",
    "    # coord_list = load_data_file( ozone_file_list )\n",
    "    # ozone_zip3_dict, ozone_state_dict = populate_dicts( coord_list )\n",
    "    multiprocessing_enable = True\n",
    "    if multiprocessing_enable == True:\n",
    "        result1 = pool.apply_async( load_data_file, [ ozone_file_list ] )\n",
    "        result2 = pool.apply_async( load_data_file, [ so2_file_list   ] )\n",
    "        result3 = pool.apply_async( load_data_file, [ co_file_list    ] )\n",
    "        result4 = pool.apply_async( load_data_file, [ no2_file_list   ] )\n",
    "\n",
    "        ozone_coord_list = result1.get(timeout=3600)\n",
    "        so2_coord_list   = result2.get(timeout=3600)\n",
    "        co_coord_list    = result3.get(timeout=3600)\n",
    "        no2_coord_list   = result4.get(timeout=3600)\n",
    "\n",
    "        result1 = pool.apply_async( populate_dicts, [ ozone_coord_list, zip3_database ] )\n",
    "        result2 = pool.apply_async( populate_dicts, [ so2_coord_list, zip3_database   ] )\n",
    "        result3 = pool.apply_async( populate_dicts, [ co_coord_list, zip3_database    ] )\n",
    "        result4 = pool.apply_async( populate_dicts, [ no2_coord_list, zip3_database   ] )\n",
    "\n",
    "        ozone_zip3_dict, ozone_state_dict = result1.get(timeout=50)\n",
    "        so2_zip3_dict,   so2_state_dict   = result2.get(timeout=50)\n",
    "        co_zip3_dict,    co_state_dict    = result3.get(timeout=50)\n",
    "        no2_zip3_dict,   no2_state_dict   = result4.get(timeout=50)\n",
    "\n",
    "    else:\n",
    "        coord_list = load_data_file( ozone_file_list )\n",
    "        ozone_zip3_dict, ozone_state_dict = populate_dicts( coord_list, zip3_database )\n",
    "        coord_list = load_data_file( ozone_file_list )\n",
    "        so2_zip3_dict, so2_state_dict = populate_dicts( coord_list, zip3_database )\n",
    "        coord_list = load_data_file( ozone_file_list )\n",
    "        co_zip3_dict, co_state_dict = populate_dicts( coord_list, zip3_database )\n",
    "        coord_list = load_data_file( ozone_file_list )\n",
    "        no2_zip3_dict, no2_state_dict = populate_dicts( coord_list, zip3_database )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print point_check(-105.002332,39.746389,zip3_database) # UCDenver\n",
    "print point_check(-104.7,39.69,zip3_database)          # Aurora, CO\n",
    "print point_check(-81.55,28.37,zip3_database)          # Epcot in Disney World\n",
    "print point_check(-77.04,38.89,zip3_database)          # Washington Monument\n",
    "print point_check(-1.826,51.18,zip3_database)          # Stonehenge, which is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print range_check(-105.002332,39.746389,1.4,'01-01-2010','12-31-2015',ozone_state_dict)\n",
    "#print range_check(-105.002332,39.746389,20,'01-01-2010','12-31-2015',ozone_state_dict)\n",
    "        \n",
    "state_graph('Colorado','01-01-2010','12-31-2015',ozone_state_dict)\n",
    "   \n",
    "zip3_graph('800','01-01-2010','12-31-2015',ozone_zip3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print range_check(-105.002332,39.746389,1.4,'01-01-2010','12-31-2015',so2_state_dict)\n",
    "#print range_check(-105.002332,39.746389,20,'01-01-2010','12-31-2015',so2_state_dict)\n",
    "    \n",
    "state_graph('Colorado','01-01-2010','12-31-2015',so2_state_dict)\n",
    "    \n",
    "zip3_graph('956','01-01-2010','12-31-2015',so2_zip3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print range_check(-105.002332,39.746389,1.4,'01-01-2010','12-31-2015',co_state_dict)\n",
    "#print range_check(-105.002332,39.746389,20,'01-01-2010','12-31-2015',co_state_dict)\n",
    "    \n",
    "state_graph('Colorado','01-01-2010','12-31-2015',co_state_dict)\n",
    "    \n",
    "zip3_graph('200','01-01-2010','12-31-2015',co_zip3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print range_check(-105.002332,39.746389,1.4,'01-01-2010','12-31-2015',no2_state_dict)\n",
    "#print range_check(-105.002332,39.746389,20,'01-01-2010','12-31-2015',no2_state_dict)\n",
    "    \n",
    "state_graph('Colorado','01-01-2010','12-31-2015',no2_state_dict)\n",
    "    \n",
    "zip3_graph('956','01-01-2010','12-31-2015',no2_zip3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print range_check(-105.002332,39.746389,1.4,'10-01-2014','12-31-2014',no2_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
